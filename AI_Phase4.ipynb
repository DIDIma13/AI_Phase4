{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "The problem at hand is to develop a fake news detection model using a dataset obtained from Kaggle. The objective is to create a system that can effectively distinguish between genuine and fake news articles based on their titles and textual content. This project requires the utilization of Natural Language Processing (NLP) techniques to preprocess and transform the text data, building a machine learning model for classification, and subsequently evaluating the model's performance.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport nltk\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Download NLTK data (if not already downloaded)\nnltk.download('stopwords')\nnltk.download('punkt')\n\n# Load the dataset (make sure you've downloaded it from Kaggle)\nfake_data = pd.read_csv(\"path_to_fake_news_dataset.csv\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Text preprocessing",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import nltk\nfrom sklearn.preprocessing import LabelEncoder\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n# Remove missing values (if any)\nfake_data = fake_data.dropna()\n\n# Combine title and text for analysis\nfake_data['text'] = fake_data['title'] + \" \" + fake_data['text']\n\n# Tokenization and stop-word removal\nstop_words = set(stopwords.words('english'))\nfake_data['text'] = fake_data['text'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word.lower() not in stop_words]))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Feature Extraction",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import TfidfVectorizer\n# Feature extraction using TF-IDF\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)\nX = tfidf_vectorizer.fit_transform(fake_data['text'])\ny = fake_data['label']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Model Training",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\n# Train the classification model\nclassifier = MultinomialNB()\nclassifier.fit(X_train, y_train)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Model Evaluation",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Evaluate the model\ny_pred = classifier.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nconfusion_mat = confusion_matrix(y_test, y_pred)\nclassification_rep = classification_report(y_test, y_pred)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Print evaluation results",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(f\"Accuracy: {accuracy}\")\nprint(\"Confusion Matrix:\")\nprint(confusion_mat)\nprint(\"Classification Report:\")\nprint(classification_rep)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Plot a confusion matrix",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(8, 6))\nsns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}